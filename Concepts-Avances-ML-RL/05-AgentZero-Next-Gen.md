# ðŸ§¬ 05. AgentZero & The Next Gen : La Convergence LLM + RL

## 1. L'Ãˆre Post-Librarie
**AgentZero** n'est pas juste un framework, c'est un manifeste.
CrÃ©Ã© pour montrer qu'un agent peut Ãªtre **auto-Ã©volutif**.
Il est "Zero" car il commence sans outils prÃ©-codÃ©s (ou presque). Il Ã©crit ses propres outils en Python, les teste, et apprend de ses erreurs.

### Cycle de Vie d'AgentZero
1.  **Code Generation** : Le LLM Ã©crit un script pour rÃ©soudre la tÃ¢che.
2.  **Execution & Trace** : Le script tourne dans un Docker. On capture stdout/stderr.
3.  **Self-Correction** : Si erreur, le LLM lit la stacktrace et rÃ©Ã©crit le code.
4.  **Memorization** : Si succÃ¨s, le code est stockÃ© dans une mÃ©moire vectorielle ("Ceci est la fonction pour scanner le web").

---

## 2. Search-on-Thought (ToT + RL)

La prochaine Ã©tape aprÃ¨s le "Prompting" est la "Recherche" (Search).
Au lieu de gÃ©nÃ©rer un seul token, l'IA gÃ©nÃ¨re un **Arbre de PensÃ©es** (Tree of Thoughts).

### L'Algorithme Q* (Q-Star) HypothÃ©tique
L'idÃ©e est d'appliquer **A* (A-Star)** ou **MCTS** sur les pensÃ©es du LLM.
*   Ã‰tat : Le texte actuel.
*   Action : La prochaine phrase.
*   Value Function $Q(s, a)$ : Est-ce que cette phrase nous rapproche de la solution ?

Ceci permet Ã  un LLM de "revenir en arriÃ¨re" (Backtrack) s'il s'aperÃ§oit qu'il a dit une bÃªtise, chose impossible avec un Transformer standard (Autoregressif "Left-to-Right").

---

## 3. Le Futur : System 1 (Intuition) + System 2 (Raisonnement)

*   **System 1 (LLM actuel)** : RÃ©ponse rapide, heuristique, parfois fausse. (Comme parler sans rÃ©flÃ©chir).
*   **System 2 (AgentZero / MuZero)** : RÃ©ponse lente, simulÃ©e, vÃ©rifiÃ©e. (Comme rÃ©soudre une Ã©quation).

L'avenir n'est pas "Plus de paramÃ¨tres". L'avenir est **"Plus de Compute au moment de l'infÃ©rence"** (Test-Time Compute).
Laisser l'agent "rÃ©flÃ©chir" (simuler 1000 chemins) pendant 30 secondes avant de donner la rÃ©ponse parfaite.

> "Training Compute is finite. Inference Compute is infinite."
