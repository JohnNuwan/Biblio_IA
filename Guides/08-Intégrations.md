# üîó Int√©grations - Connecter les LLMs √† vos Outils

## 1. APIs des Principaux LLMs

### OpenAI (GPT)
```python
from openai import OpenAI
client = OpenAI(api_key="sk-...")

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "Tu es un assistant."},
        {"role": "user", "content": "Bonjour !"}
    ]
)
print(response.choices[0].message.content)
```

### Anthropic (Claude)
```python
import anthropic
client = anthropic.Anthropic(api_key="sk-...")

response = client.messages.create(
    model="claude-3-sonnet-20240229",
    max_tokens=1024,
    messages=[{"role": "user", "content": "Bonjour !"}]
)
print(response.content[0].text)
```

### Google (Gemini)
```python
import google.generativeai as genai
genai.configure(api_key="...")

model = genai.GenerativeModel('gemini-pro')
response = model.generate_content("Bonjour !")
print(response.text)
```

---

## 2. LLMs Locaux (Self-Hosted)

### ü¶ô Ollama (Facile √† utiliser)

**Installation :**
```bash
# Windows/Mac/Linux
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©charger un mod√®le
ollama pull llama3
ollama pull mistral
ollama pull codellama
```

**Utilisation CLI :**
```bash
ollama run llama3 "Explique le machine learning"
```

**API REST (compatible OpenAI) :**
```python
from openai import OpenAI

# Ollama expose une API compatible OpenAI !
client = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"  # Pas besoin de vraie cl√©
)

response = client.chat.completions.create(
    model="llama3",
    messages=[{"role": "user", "content": "Bonjour !"}]
)
print(response.choices[0].message.content)
```

**Avantages Ollama :**
- ‚úÖ Installation en 1 commande
- ‚úÖ API compatible OpenAI
- ‚úÖ Gestion automatique des mod√®les
- ‚úÖ Id√©al pour dev/prototypage

---

### ‚ö° vLLM (Production & Performance)

**Installation :**
```bash
pip install vllm
```

**Lancer un serveur :**
```bash
python -m vllm.entrypoints.openai.api_server \
    --model mistralai/Mistral-7B-Instruct-v0.2 \
    --host 0.0.0.0 \
    --port 8000
```

**Utilisation (API OpenAI compatible) :**
```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="token-abc123"
)

response = client.chat.completions.create(
    model="mistralai/Mistral-7B-Instruct-v0.2",
    messages=[{"role": "user", "content": "Bonjour !"}]
)
```

**Avantages vLLM :**
- ‚ö° Tr√®s rapide (PagedAttention)
- üìà Haute concurrence
- üîß Production-ready
- üê≥ Docker disponible

---

### Comparatif Ollama vs vLLM

| Crit√®re | Ollama | vLLM |
|---------|--------|------|
| Installation | ‚≠ê‚≠ê‚≠ê Tr√®s facile | ‚≠ê‚≠ê Technique |
| Performance | ‚≠ê‚≠ê Bonne | ‚≠ê‚≠ê‚≠ê Excellente |
| Usage | Dev, prototypage | Production |
| Concurrence | Moyenne | Haute |
| GPU requis | Optionnel | Recommand√© |

---

## 3. Plateformes No-Code

### Zapier
| Use Case | Configuration |
|----------|---------------|
| Email ‚Üí LLM ‚Üí R√©ponse | Trigger Gmail ‚Üí OpenAI ‚Üí Send Email |
| Form ‚Üí LLM ‚Üí Sheet | Typeform ‚Üí Claude ‚Üí Google Sheets |
| Slack ‚Üí LLM ‚Üí Slack | New message ‚Üí GPT ‚Üí Reply |

### Make (Integromat)
- Plus flexible que Zapier
- Meilleur pour les workflows complexes
- Module OpenAI natif

### n8n (Self-hosted)
- Open source
- Peut √™tre h√©berg√© en interne
- Id√©al pour la confidentialit√©

---

## 3. Int√©grations Courantes

### üìß Email Automation
```
Trigger: Nouvel email re√ßu
‚Üí Analyser avec LLM (intention, urgence)
‚Üí Cat√©goriser automatiquement
‚Üí G√©n√©rer brouillon de r√©ponse
```

### üìä Excel/Sheets
```
Trigger: Nouvelle ligne
‚Üí LLM analyse le contenu
‚Üí Enrichit avec des colonnes calcul√©es
‚Üí Met √† jour le fichier
```

### üí¨ Chat/Support
```
Message client
‚Üí RAG sur documentation
‚Üí LLM g√©n√®re r√©ponse
‚Üí Envoi au client (ou validation humaine)
```

### üìù Documents
```
Document upload√©
‚Üí OCR si image/PDF
‚Üí LLM extrait les infos cl√©s
‚Üí Stocke en base structur√©e
```

---

## 4. Frameworks Agents

### LangChain (Python/JS)
```python
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, Tool

llm = ChatOpenAI(model="gpt-4")
tools = [Tool(name="Search", func=search_fn, description="...")]
agent = initialize_agent(tools, llm, agent="zero-shot-react")
agent.run("Quelle est la capitale de la France ?")
```

### LlamaIndex
Sp√©cialis√© RAG
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader

documents = SimpleDirectoryReader('data').load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()
response = query_engine.query("Question ?")
```

### CrewAI
Multi-agents
```python
from crewai import Agent, Task, Crew

researcher = Agent(role="Researcher", goal="...")
writer = Agent(role="Writer", goal="...")
crew = Crew(agents=[researcher, writer], tasks=[...])
crew.kickoff()
```

---

## 5. Bases Vectorielles (pour RAG)

| Base | Type | Usage |
|------|------|-------|
| **ChromaDB** | Local/Hosted | Prototypage, petits volumes |
| **Pinecone** | Cloud | Production, scalabilit√© |
| **Weaviate** | Self-hosted | Contr√¥le total |
| **Qdrant** | Self-hosted | Haute performance |
| **Milvus** | Enterprise | Gros volumes |

### Exemple ChromaDB
```python
import chromadb
client = chromadb.Client()
collection = client.create_collection("docs")
collection.add(
    documents=["Doc 1", "Doc 2"],
    ids=["id1", "id2"]
)
results = collection.query(query_texts=["Ma question"], n_results=3)
```

---

## 6. D√©ploiement

### Options
| Option | Quand l'utiliser |
|--------|------------------|
| **API directe** | Prototypage, MVPs |
| **Serverless** (Lambda) | Usage variable |
| **Container** (Docker) | Contr√¥le, scaling |
| **Managed** (Vercel, Railway) | Rapidit√© |

### Variables d'Environnement
```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-...
GOOGLE_API_KEY=...
```

‚ö†Ô∏è **Ne jamais commit les cl√©s API dans le code !**

---

## 7. S√©curit√© & Bonnes Pratiques

| Risque | Mitigation |
|--------|------------|
| Fuite de cl√© API | Variables d'environnement |
| Injection de prompt | Valider les entr√©es |
| Co√ªts incontr√¥l√©s | Rate limiting, budgets |
| Donn√©es sensibles | Ne pas envoyer au cloud |
