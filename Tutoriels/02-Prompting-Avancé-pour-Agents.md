# üß† Tutoriel 2 : Prompting Avanc√© pour Agents IA

Un Agent n'est aussi intelligent que les instructions qu'on lui donne. Contrairement √† un simple Chatbot, un Agent a besoin d'instructions **extr√™mement pr√©cises** (System Prompts) pour manipuler des outils sans tout casser.

## 1. L'Anatomie d'un System Prompt Robuste

Pour un Agent, le prompt syst√®me doit d√©finir 4 piliers :
1. **Persona** : Qui il est (Expert, Support, Encodeur...).
2. **Objectif** : Ce qu'il doit accomplir globalement.
3. **Outils & Contraintes** : Comment utiliser les outils et ce qu'il est INTERDIT de faire.
4. **Format de Sortie** : JSON, ReAct, XML...

### Exemple de "Mauvais" Prompt
> "Tu es un assistant utile. Tu as acc√®s √† Google Search. R√©ponds aux questions."

‚ùå **Probl√®me** : L'agent va "bavarder" au lieu d'agir. Il ne sait pas *quand* chercher.

### Exemple de "Bon" Prompt
> "Tu es un Analyste de Recherche Senior. Ton but est de fournir des r√©ponses factuelles bas√©es UNIQUEMENT sur des donn√©es r√©centes.
> Tu DOIS utiliser l'outil `google_search` si tu n'es pas s√ªr √† 100% d'une information.
> NE r√©ponds JAMAIS par tes propres connaissances pr√©-2023 sans v√©rifier.
> R√©ponds toujours en format Markdown structur√©."

## 2. D√©crire ses Outils (La partie la plus critique)

Les LLMs modernes (GPT-4) lisent la description de vos fonctions pour savoir quoi envoyer. Une description floue = des erreurs d'arguments.

### ‚ùå Description Floue
```python
def search_db(query):
    """Cherche dans la base de donn√©es."""
```
Le LLM ne sait pas : Quelle syntaxe ? SQL ? Mots-cl√©s ? Id ?

### ‚úÖ Description Optimis√©e pour Agent
```python
def search_db(user_id, status="active"):
    """
    Recherche les commandes d'un utilisateur sp√©cifique.
    Args:
        user_id (str): L'ID unique (ex: 'USER_123'). Ne pas inventer d'ID.
        status (str): Filtre par statut ('active', 'shipped', 'cancelled'). D√©faut: 'active'.
    Returns:
        JSON string des commandes trouv√©es.
    """
```
üí° **Astuce** : Donnez des exemples de valeurs dans la docstring. Le LLM les lira.

## 3. Techniques de Robustesse

### A. "Failsafe" (Gestion d'√©chec)
Dites √† l'Agent quoi faire si un outil √©choue.

> "Si l'outil `search_db` renvoie 'Erreur', N'INVENTE PAS de r√©ponse. Dis √† l'utilisateur que la base est inaccessible et propose de r√©essayer plus tard."

### B. "Chain of Verification"
Forcez l'agent √† rev√©rifier son plan.

> "Avant d'appeler un outil destructeur (ex: `delete_file`), tu DOIS g√©n√©rer une pens√©e 'Thought: Je vais supprimer X, est-ce bien demand√© ?' et attendre une confirmation."

## 4. Structurer la Sortie (JSON Mode)

Pour int√©grer un agent dans une app, le texte libre est un cauchemar. Forcez le JSON.

```json
SYSTEM PROMPT ADDITION:
Tes r√©ponses finales doivent √™tre au format JSON strict :
{
  "thought": "Ton raisonnement ici",
  "action_needed": true/false,
  "response": "Texte pour l'utilisateur"
}
```

## Exercice Pratique

Reprenez l'agent du Tutoriel 1 et modifiez le `SYSTEM_PROMPT` pour qu'il refuse de r√©pondre aux questions sur la politique, et qu'il r√©ponde toujours en rimes.

C'est le pouvoir du Prompting Agentique : **Le code reste le m√™me, mais le comportement change radicalement juste avec du texte.**
